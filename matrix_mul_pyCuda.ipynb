{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMxqP8KWM3uwIY60G/Pj7X5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fyr-repo/parallel_programming_intro/blob/main/matrix_mul_pyCuda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe-Lwwxgobck",
        "outputId": "7ff78057-914c-4ac9-aa2b-94e60b2f85b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "! nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install nvcc4jupyter\n",
        "! pip install pycuda\n",
        "\n",
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4eOle2lorFc",
        "outputId": "217e0b4d-5dfd-4b32-ec94-ab0062ffc511"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nvcc4jupyter in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: pycuda in /usr/local/lib/python3.10/dist-packages (2024.1)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.10/dist-packages (from pycuda) (2023.1.1)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.4.4)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.3.2)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.10.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.5)\n",
            "Source files will be saved in \"/tmp/tmp0394jrrh\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pycuda.autoinit\n",
        "import pycuda.driver as cuda\n",
        "from pycuda.compiler import SourceModule"
      ],
      "metadata": {
        "id": "l6yUAXr6p7oj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pycuda import gpuarray, tools, compiler"
      ],
      "metadata": {
        "id": "YLy9xY8hsiYX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "r8remQcqy0o4"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_code_template = \"\"\"\n",
        "__global__ void matrixmulti(int matrixsize,float *a, float *b, float *c)\n",
        "{\n",
        "\n",
        "    // 2D Thread ID\n",
        "    int tx = blockDim.x*blockIdx.x + threadIdx.x; // Compute column index\n",
        "    int ty = blockDim.y*blockIdx.y + threadIdx.y; // Compute row index\n",
        "\n",
        "    // Each thread loads one row of M and one column of N,\n",
        "    //   to produce one element of P.\n",
        "    if((ty <matrixsize) && (tx < matrixsize))\n",
        "    {\n",
        "    // Pvalue is used to store the element of the matrix\n",
        "    // that is computed by the thread\n",
        "    float Pvalue = 0;\n",
        "    for(int k=0; k<matrixsize;++k)\n",
        "    {\n",
        "    float Aelement = a[ty*matrixsize +k];\n",
        "    float Belement = b[k*matrixsize +tx];\n",
        "    Pvalue += Aelement * Belement;\n",
        "    }\n",
        "    c[ty * matrixsize + tx] = Pvalue;\n",
        "    }\n",
        "\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "kwcjcBdLyX8L"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the dimensions and values of the arrays\n",
        "rows_cols = 1000\n",
        "value = 55.55\n",
        "\n",
        "BLOCK_SIZE = 32\n",
        "\n",
        "# Create the input arrays filled with the specified value\n",
        "array1 = np.full((rows_cols, rows_cols), value).astype(np.float32)\n",
        "array2 = np.full((rows_cols, rows_cols), value).astype(np.float32)\n",
        "\n",
        "# Measure the start time\n",
        "start_time = time.time()\n",
        "\n",
        "array1_gpu = gpuarray.to_gpu(array1)\n",
        "array2_gpu = gpuarray.to_gpu(array2)\n",
        "\n",
        "result_gpu = gpuarray.empty((rows_cols, rows_cols), np.float32)\n",
        "\n",
        "\n",
        "\n",
        "# compile the kernel code\n",
        "mod = compiler.SourceModule(kernel_code_template)\n",
        "\n",
        "# get the kernel function from the compiled module\n",
        "matrixmul = mod.get_function(\"matrixmulti\")\n",
        "\n",
        "MATRIX_SIZE = rows_cols\n",
        "\n",
        "# set grid size\n",
        "if MATRIX_SIZE%BLOCK_SIZE != 0:\n",
        "    grid=(MATRIX_SIZE//BLOCK_SIZE+1,MATRIX_SIZE//BLOCK_SIZE+1,1)\n",
        "else:\n",
        "    grid=(MATRIX_SIZE//BLOCK_SIZE,MATRIX_SIZE//BLOCK_SIZE,1)\n",
        "\n",
        "matrixsize=MATRIX_SIZE\n",
        "# call the kernel on the card\n",
        "matrixmul(np.uint32(matrixsize),\n",
        "    # inputs\n",
        "    array1_gpu, array2_gpu,\n",
        "    # output\n",
        "\n",
        "    result_gpu,\n",
        "    grid=grid,\n",
        "    block = (BLOCK_SIZE, BLOCK_SIZE, 1),\n",
        "    )\n",
        "\n",
        "# Measure the end time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the time taken for processing\n",
        "processing_time = end_time - start_time\n",
        "\n",
        "# Print the result and time taken for processing\n",
        "print(\"Matrix multiplication result:\")\n",
        "print(result_gpu.get())\n",
        "print(f\"Time taken for processing: {processing_time:.4f} seconds\")\n",
        "\n",
        "# np.allclose(result_gpu, result_gpu.get())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2oJDsAvqaG7",
        "outputId": "66e5597f-fb09-444d-f084-34ed40c6fcf9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix multiplication result:\n",
            "[[3085770.2 3085770.2 3085770.2 ... 3085770.2 3085770.2 3085770.2]\n",
            " [3085770.2 3085770.2 3085770.2 ... 3085770.2 3085770.2 3085770.2]\n",
            " [3085770.2 3085770.2 3085770.2 ... 3085770.2 3085770.2 3085770.2]\n",
            " ...\n",
            " [3085770.2 3085770.2 3085770.2 ... 3085770.2 3085770.2 3085770.2]\n",
            " [3085770.2 3085770.2 3085770.2 ... 3085770.2 3085770.2 3085770.2]\n",
            " [3085770.2 3085770.2 3085770.2 ... 3085770.2 3085770.2 3085770.2]]\n",
            "Time taken for processing: 0.0039 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: device_allocation in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n",
            "/usr/local/lib/python3.10/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: module in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EPyW5GibtDSk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}